---
title: "Bedrock Provider"
description: "The Bedrock Provider allows for integrating AWS Bedrock foundation models into Keep."
---
import AutoGeneratedSnippet from '/snippets/providers/bedrock-snippet-autogenerated.mdx';

<Tip>
  The Bedrock Provider supports querying multiple foundation models including Anthropic Claude, Meta Llama, and Amazon Titan for prompt-based interactions.
</Tip>

## Outputs

The Bedrock Provider outputs the response from the foundation model based on the prompt provided. Supports structured JSON output when configured.

## Supported Models

- **Anthropic Claude**: Uses Messages API format with system prompts
- **Meta Llama**: Prompt-based generation with configurable parameters
- **Amazon Titan Text**: Text generation with configurable parameters

## Connecting with the Provider

The Bedrock Provider supports two authentication methods:

### 1. SSO/IAM Role Authentication (Recommended)
Leave `access_key` and `secret_access_key` empty to use AWS SSO or IAM role authentication:

```yaml
authentication:
  access_key: null
  secret_access_key: null
  region: "us-east-1"
```

### 2. Access Key Authentication
Provide explicit AWS credentials:

```yaml
authentication:
  access_key: "your-access-key"
  secret_access_key: "your-secret-key"
  region: "us-east-1"
```

## Required Permissions

Your AWS credentials must have the following permissions:
- `bedrock:ListFoundationModels`
- `bedrock:InvokeModel`

## Configuration Parameters

- **model**: Foundation model ID (default: `meta.llama3-3-70b-instruct-v1:0`)
- **max_tokens**: Maximum tokens to generate (default: 1024)
- **temperature**: Controls randomness (0.0-1.0, default: 0.7)
- **top_p**: Controls diversity (0.0-1.0, default: 0.9)
- **structured_output_format**: JSON schema for structured responses

<AutoGeneratedSnippet />